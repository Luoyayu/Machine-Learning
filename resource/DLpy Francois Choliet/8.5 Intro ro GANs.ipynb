{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to generative adversarial networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "\u001b[1m\u001b[31mtensorflow          1.11.0              \u001b[0m\n",
      "\u001b[1m\u001b[32mkeras               2.2.4               \u001b[0m\n",
      "\u001b[1m\u001b[33mtorch               1.0.0.dev20180929   \u001b[0m\n",
      "\u001b[1m\u001b[34msklearn             0.20.0              \u001b[0m\n",
      "\u001b[1m\u001b[35mnumpy               1.15.2              \u001b[0m\n",
      "\u001b[1m\u001b[36mscipy               1.1.0               \u001b[0m\n",
      "\u001b[1m\u001b[31mpandas              0.23.4              \u001b[0m\n",
      "\u001b[1m\u001b[32mmatplotlib          3.0.0               \u001b[0m\n",
      "\u001b[1m\u001b[33mcv2                 3.4.2               \u001b[0m\n",
      "\u001b[1m\u001b[34mPIL                 5.3.0               \u001b[0m\n",
      "\u001b[1m\u001b[35mIPython             6.2.1               \u001b[0m\n",
      "\u001b[1m\u001b[36mjupyterlab          0.35.1              \u001b[0m\n",
      "\u001b[5m\u001b[31msys platform: darwin\u001b[0m\n",
      "\u001b[5m\u001b[32msys.version_info(major=3, minor=6, micro=6, releaselevel='final', serial=0)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 ../testenv.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\mathrm{GAN}$ 组成  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 生成网络 ($\\mathrm{Generator\\;network}$)  \n",
    "2. 辨别网络 ($\\mathrm{Discriminator\\;network}$)  \n",
    "![](https://i.loli.net/2018/10/27/5bd3d83e0424f.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\mathrm{A\\; schematic \\;GAN\\; implementation}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High Leve API: Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> $\\mathbf{model:}$ $\\mathrm{deep \\;convolutional \\;GAN \\;}$ $\\mathbf{(DCGAN)} $  \n",
    "$\\mathbf{dataset:}$ :CIFAR10, a dataset of $50,000\\; 32 \\times 32$ RGB images belonging to $10$ classes ($5,000$ images per class).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DCGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. A **generator network** maps vectors of shape $\\text{(latent_dim,)}$ to images of shape $(32, 32, 3)$.  \n",
    "2. A **discriminator network** maps images of shape (32, 32, 3) to a binary score estimating the probability that the image is real.  \n",
    "3. A **gan network** chains the generator and the discriminator together: $\\mathbf{gan(x) = discriminator(generator(x))}$\n",
    ">Thus this **gan network** maps latent space vectors to the discriminator’s assessment of the realism of these latent vectors as decoded by the generator.\n",
    "4. train the **discriminator** using examples of real and fake images along with `“real”/“fake”` labels  \n",
    "5. train the **generator**, using the gradients of the generator’s weights with regard to the loss of the gan model.\n",
    ">train the **generator** to fool the discriminator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"Alchemy\"\n",
    "1. using `tanh` as the last activation in the generator\n",
    "2. sample points from the latent space using a `normal distribution`\n",
    "3. Stochasticity, aka Xuanxue  \n",
    ">GANs are likely to get stuck in all sorts of ways and stochasticity is good to induce robustness. \n",
    "4. no `Sparse gradients` \n",
    ">if you alreadly use max pooling operations and ReLU activations in network, here recommend using a `LeakyReLU`\n",
    "5.unequal coverage of the pixel space in the generator, make sure kernel size that’s divisible by the stride size whenever we use a strided Conv2DTranpose or Conv2D in both the generator and the discriminator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### $\\mathrm{GAN \\;generator\\; network}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32768)             1081344   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 256)       819456    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 32, 32, 256)       1048832   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 256)       1638656   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 256)       1638656   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 3)         37635     \n",
      "=================================================================\n",
      "Total params: 6,264,579\n",
      "Trainable params: 6,264,579\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "\n",
    "latent_dim = 32\n",
    "h, w, channels = 32, 32, 3\n",
    "\n",
    "# 输入32维随机向量\n",
    "generator_input = keras.Input(shape=(latent_dim,))\n",
    "\n",
    "# 全连接层\n",
    "x = layers.Dense(128*16*16)(generator_input)\n",
    "# 激活函数层 LeakyReLU\n",
    "x = layers.LeakyReLU()(x)\n",
    "# Reshape层\n",
    "x = layers.Reshape((16, 16, 128))(x)\n",
    "\n",
    "# 256个5×5卷积核，保持图像尺寸\n",
    "x = layers.Conv2D(filters=256, kernel_size=5, padding='same')(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "# 转置卷积层，256个4×4卷积核，\n",
    "x = layers.Conv2DTranspose(filters=256, kernel_size=4, strides=2, padding='same')(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "# 两层 256个大小为5×5的卷积核\n",
    "x = layers.Conv2D(filters=256, kernel_size=5, padding='same')(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2D(filters=256, kernel_size=5, padding='same')(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "# 输出卷积层，3个大小为7×7的卷积核，输出为32×32×3\n",
    "x = layers.Conv2D(channels, kernel_size=7, activation='tanh', padding='same')(x)\n",
    "generator=keras.models.Model(generator_input, x)\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### $\\mathrm{GAN \\;discriminator\\; network}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 30, 30, 128)       3584      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 30, 30, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 14, 14, 128)       262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 6, 6, 128)         262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 2, 2, 128)         262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 790,913\n",
      "Trainable params: 790,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator_input = layers.Input(shape=(h, w, channels))\n",
    "\n",
    "x = layers.Coznv2D(128, 3)(discriminator_input)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "x = layers.Conv2D(128, 4, strides=2)(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "x = layers.Conv2D(128, 4, strides=2)(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "x = layers.Conv2D(128, 4, strides=2)(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "# Dropout技术\n",
    "x = layers.Dropout(0.4)(x)\n",
    "\n",
    "# sigmoid 分类器\n",
    "x = layers.Dense(units=1, activation='sigmoid')(x)\n",
    "\n",
    "discriminator = keras.models.Model(discriminator_input, x)\n",
    "\n",
    "discriminator_optimizer = keras.optimizers.RMSprop(\n",
    "    lr=0.0008,\n",
    "    clipvalue=1.0,\n",
    "    decay=1e-8)\n",
    "discriminator.compile(optimizer=discriminator_optimizer, loss='binary_crossentropy')\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### $\\mathrm{Adversarial \\;network}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "model_1 (Model)              (None, 32, 32, 3)         6264579   \n",
      "_________________________________________________________________\n",
      "model_2 (Model)              (None, 1)                 790913    \n",
      "=================================================================\n",
      "Total params: 7,055,492\n",
      "Trainable params: 6,264,579\n",
      "Non-trainable params: 790,913\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator.trainable = False\n",
    "\n",
    "gan_input = keras.Input(shape=(latent_dim,))\n",
    "gan_output = discriminator(generator(gan_input))\n",
    "gan = keras.models.Model(gan_input, gan_output)\n",
    "\n",
    "gan_optimizer = keras.optimizers.RMSprop(\n",
    "    lr=0.0004,\n",
    "    clipvalue=1.0,\n",
    "    decay=1e-8)\n",
    "gan.compile(optimizer=gan_optimizer, loss='binary_crossentropy')\n",
    "gan.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### $\\mathrm{train\\;model}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Draw random points in the latent space (random noise).   \n",
    "2. Generate images with generator using this random noise.   \n",
    "3. Mix the generated images with real ones.  \n",
    "4. Train discriminator using these mixed images, with corresponding targets:  \n",
    "5. Draw new random points in the latent space.  \n",
    "6. Train gan using these random vectors, only updates the weights of the generator  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/ml/lib/python3.6/site-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator loss 8.393893\n",
      "adversarial loss 15.838412\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-ffea9bcceea7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mmisleading_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0ma_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_letent_vectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmisleading_targets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/ml/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/ml/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/ml/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/ml/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1397\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1398\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1399\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1400\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "from keras.preprocessing import image\n",
    "(x_tranin, y_train), (_,_) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "x_tranin = x_tranin[y_train.flatten() == 6]\n",
    "\n",
    "x_tranin = x_tranin.reshape(\n",
    "    (x_tranin.shape[0],)+(h, w, channels)\n",
    ").astype('float32') / 255.0\n",
    "iterations = 10000\n",
    "batch_size = 20\n",
    "save_dir = './tmp'\n",
    "\n",
    "start = 0\n",
    "for step in range(iterations):\n",
    "    random_letent_vectors = np.random.normal(size=(batch_size, latent_dim))\n",
    "    \n",
    "    generated_images = generator.predict(random_letent_vectors)\n",
    "    \n",
    "    stop = start + batch_size\n",
    "    real_images = x_tranin[start: stop]\n",
    "    combined_images = np.concatenate([generated_images, real_images])\n",
    "    \n",
    "    labels = np.concatenate([np.ones((batch_size, 1)),\n",
    "                            np.zeros((batch_size, 1))])\n",
    "    labels += 0.05 * np.random.random(labels.shape) # add some noise to labels\n",
    "    \n",
    "    d_loss = discriminator.train_on_batch(combined_images, labels)\n",
    "    \n",
    "    random_letent_vectors = np.random.normal(size=(batch_size, latent_dim))\n",
    "    \n",
    "    misleading_targets = np.zeros((batch_size, 1))\n",
    "    \n",
    "    a_loss = gan.train_on_batch(random_letent_vectors, misleading_targets)\n",
    "    \n",
    "    start += batch_size\n",
    "    if start > len(x_tranin) - batch_size:\n",
    "        start = 0\n",
    "    if step % 100 ==0:\n",
    "        gan.save_weights('gan.h5')\n",
    "        \n",
    "        print('discriminator loss', d_loss)\n",
    "        print('adversarial loss', a_loss)\n",
    "        \n",
    "        img = image.array_to_img(generated_images[0] * 255., scale=False)\n",
    "        img.save(os.path.join(save_dir, 'real_frog' + str(step) + '.png'))\n",
    "        \n",
    "        img = image.array_to_img(real_images[0] * 255., scale=False)\n",
    "        img.save(os.path.join(save_dir, 'real_frog' + str(step) + '.png'))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Reshape\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import UpSampling2D\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers.core import Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import argparse\n",
    "import math\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 生成器网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_model():\n",
    "    \"\"\"\n",
    "    定义可生成图像的模型G(z;θ_g)\n",
    "    \"\"\"\n",
    "    # 序贯模型\n",
    "    model = Sequential()\n",
    "    # 全连接层，输入为100维向量， 输出1024维\n",
    "    model.add(Dense(input_dim=100, output_dim=1024))\n",
    "    # 激活函数tanh\n",
    "    model.add(Activation('tanh'))\n",
    "    # 全连接层，输出为128*7*7维\n",
    "    model.add(Dense(units=128*7*7))\n",
    "    # 批量归一化层, 每个batch上将前一层的激活值规范化\n",
    "    model.add(BatchNormalization())\n",
    "    # 激活函数tanh\n",
    "    model.add(Activation('tanh'))\n",
    "    # 128*7*7 vector to 7×7×128 Tonsor\n",
    "    model.add(Reshape(target_shape=(7,7,128), input_shape=(128*7*7,None))) # 7×7×128\n",
    "    # 2维上采样，与上池化的区别是用该数字填充，而非0\n",
    "    model.add(UpSampling2D(size=(2,2))) # 14×14×128\n",
    "    # 2维卷积核，大小为5×5, 激活函数tanh, 64个卷积核，padding保持图像尺寸不变\n",
    "    model.add(Conv2D(filters=64,kernel_size=(5,5), padding='same')) # 28×28×64\n",
    "    model.add(Activation('tanh'))\n",
    "    # 2维上采样\n",
    "    model.add(UpSampling2D(size=(2,2)))\n",
    "    # 卷积核为1输出图像的维度\n",
    "    model.add(Conv2D(filters=1, kernel_size=(5,5), padding='same')) # 28×28×1\n",
    "    model.add(Activation('tanh'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 拼接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_containing_discriminator(g, d):\n",
    "    \"\"\"\n",
    "    训练生成模型时固定判别器以极小化maxV(G,D*),\n",
    "    组合生成器、判别器\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    # \n",
    "    model.add(g)\n",
    "    # \n",
    "    d.trainable = False\n",
    "    model.add(d)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_images(generated_images):\n",
    "    #生成图片拼接\n",
    "    num = generated_images.shape[0]\n",
    "    width = int(math.sqrt(num))\n",
    "    height = int(math.ceil(float(num)/width))\n",
    "    shape = generated_images.shape[1:3]\n",
    "    image = np.zeros((height*shape[0], width*shape[1]),dtype=generated_images.dtype)\n",
    "    for index, img in enumerate(generated_images):\n",
    "        i = int(index/width)\n",
    "        j = index % width\n",
    "        image[i*shape[0]:(i+1)*shape[0], j*shape[1]:(j+1)*shape[1]] = img[:, :, 0]\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 判别器网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_model():\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(\n",
    "        Conv2D(\n",
    "          filters=64, \n",
    "          kernel_size=(5, 5),\n",
    "          padding='same', \n",
    "          input_shape=(28, 28, 1))\n",
    "        )\n",
    "    model.add(Activation('tanh'))\n",
    "    #最大值池化层\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Conv2D(filters=128, kernel_size=(5,5)))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    # 一维化，卷积层到全连接层的过渡\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=1024))\n",
    "    model.add(Activation('tanh'))\n",
    "    # 二维分类器\n",
    "    model.add(Dense(units=1))\n",
    "    model.add(Activation(activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(BATCH_SIZE):\n",
    "    (X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "    print('X_train shape is ', X_train.shape) # (60000, 28, 28)\n",
    "    print('y_train shape is ', y_train.shape) # (60000,)\n",
    "    \n",
    "    X_train = (X_train.astype(np.float32)-127.5)/127.5\n",
    "    X_train = X_train[:, :, :, None] # (60000, 28, 28, 1) => 28×28×1\n",
    "    X_test = X_test[:, :, :, None]\n",
    "    \n",
    "    # 定义模型\n",
    "    d = discriminator_model()\n",
    "    g = generator_model()\n",
    "    d_on_g = generator_containing_discriminator(g, d) # fixed d to min maxV(G,D*)\n",
    "    \n",
    "    # 定义优化器\n",
    "    d_optim = SGD(lr=0.001, momentum=0.9, nesterov=True)\n",
    "    g_optim = SGD(lr=0.001, momentum=0.9, nesterov=True)\n",
    "    \n",
    "    # 编译模型\n",
    "    g.compile(loss='binary_crossentropy', optimizer='SGD')\n",
    "    d_on_g.compile(loss='binary_crossentropy', optimizer=g_optim)\n",
    "    \n",
    "    # 固定判别器训练出了生成器后启动判别器网络\n",
    "    d.trainable = True\n",
    "    d.compile(loss='binary_crossentropy', optimize=d_optim)\n",
    "    \n",
    "    for epoch in range(30):\n",
    "        print('Epoch is ', epoch)\n",
    "        print('Number of batches', int(X_train.shape[0]//BATCH_SIZE))\n",
    "        \n",
    "        for idx in range(int(X_train.shape[0]//BATCH_SIZE)):\n",
    "            # 生成均匀分布的噪声 BATCH_SIZE×100\n",
    "            noise = np.random.uniform(min=-1.0, max=1.0, size=(BATCH_SIZE,100))\n",
    "            # 抽泣一个batch的真实图片集\n",
    "            img_batch = X_train[idx*BATCH_SIZE:(idx+1)*BATCH_SIZE]\n",
    "            generated_img = g.predict(noise, verbose=0) # no log\n",
    "            if idx % 100 == 0:\n",
    "                img = combine_images(generated_img)\n",
    "                img = img * 127.5 + 127.5\n",
    "                Image.fromarray(img.astype(np.uint8)).save('./GAN/'+str(epoch)+\"_\"+str(idx)+'.png')\n",
    "                # 组合真实图片和生成图片\n",
    "                X = np.concatenate((img_batch, generated_img))\n",
    "                # 产生图片标签\n",
    "                y = [1] * BATCH_SIZE + [0] * BATCH_SIZE\n",
    "                d_loss = d.train_on_batch(X, y)\n",
    "                print(\"batch %d d_loss : %f\" % (index, d_loss))\n",
    "\n",
    "                #随机生成的噪声服从均匀分布\n",
    "                noise = np.random.uniform(-1, 1, (BATCH_SIZE, 100))\n",
    "\n",
    "                #固定判别器\n",
    "                d.trainable = False\n",
    "\n",
    "                #计算生成器损失；在一个batch的数据上进行一次参数更新\n",
    "                g_loss = d_on_g.train_on_batch(noise, [1] * BATCH_SIZE)\n",
    "\n",
    "                #令判别器可训练\n",
    "                d.trainable = True\n",
    "                print(\"batch %d g_loss : %f\" % (index, g_loss))\n",
    "\n",
    "                #每100次迭代保存一次生成器和判别器的权重\n",
    "                if index % 100 == 9:\n",
    "                    g.save_weights('generator', True)\n",
    "                    d.save_weights('discriminator', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(BATCH_SIZE, nice= False ):\n",
    "    #训练完模型后，可以运行该函数生成图片\n",
    "    g = generator_model()\n",
    "    g.compile(loss='binary_crossentropy', optimizer=\"SGD\")\n",
    "    g.load_weights('generator')\n",
    "    if nice:\n",
    "        d = discriminator_model()\n",
    "        d.compile(loss='binary_crossentropy', optimizer=\"SGD\")\n",
    "        d.load_weights('discriminator')\n",
    "        noise = np.random.uniform(-1, 1, (BATCH_SIZE*20, 100))\n",
    "        generated_images = g.predict(noise, verbose=1)\n",
    "        d_pret = d.predict(generated_images, verbose=1)\n",
    "        index = np.arange(0, BATCH_SIZE*20)\n",
    "        index.resize((BATCH_SIZE*20, 1))\n",
    "        pre_with_index = list(np.append(d_pret, index, axis=1))\n",
    "        pre_with_index.sort(key=lambda x: x[0], reverse=True)\n",
    "        nice_images = np.zeros((BATCH_SIZE,) + generated_images.shape[1:3], dtype=np.float32)\n",
    "        nice_images = nice_images[:, :, :, None]\n",
    "        for i in range(BATCH_SIZE):\n",
    "            idx = int(pre_with_index[i][1])\n",
    "            nice_images[i, :, :, 0] = generated_images[idx, :, :, 0]\n",
    "        image = combine_images(nice_images)\n",
    "    else:\n",
    "        noise = np.random.uniform(-1, 1, (BATCH_SIZE, 100))\n",
    "        generated_images = g.predict(noise, verbose=0)\n",
    "        image = combine_images(generated_images)\n",
    "    image = image*127.5+127.5\n",
    "    Image.fromarray(image.astype(np.uint8)).save(\n",
    "        \"./GAN/generated_image.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate(132)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
